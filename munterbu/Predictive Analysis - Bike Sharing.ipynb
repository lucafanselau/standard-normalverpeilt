{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rides = pd.read_csv(\"chicago_2018.csv\", sep=\",\")\n",
    "\n",
    "Rides[\"start_time\"] = pd.to_datetime(Rides[\"start_time\"])\n",
    "Rides[\"end_time\"] = pd.to_datetime(Rides[\"end_time\"])\n",
    "\n",
    "Rides.sort_values(\"start_time\", inplace = True)\n",
    "Rides.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is just for double checking the aggregated, hourly rental counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = datetime.datetime(year=2018, month=1, day=1, hour = 5)\n",
    "date2 = datetime.datetime(year=2018, month=1, day=1, hour = 6)\n",
    "\n",
    "Rides[(Rides[\"start_time\"] >= date1) & (Rides[\"start_time\"] <= date2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the hourly demand for 2018. The result is stored in a DataFrame of 24 by 365 = 8760 rows, neglecting time change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_index = date1 + pd.to_timedelta(np.arange(8760), 'H')\n",
    "\n",
    "Features = pd.DataFrame(index = date_index)\n",
    "\n",
    "Features[\"demand\"] = 0\n",
    "\n",
    "Features = Rides.set_index(\"start_time\")\n",
    "Features = Features.resample('H').count()\n",
    "\n",
    "Features.drop(columns = \"start_station_id\", inplace = True)\n",
    "Features.drop(columns = \"end_station_id\", inplace = True)\n",
    "Features.drop(columns = \"start_station_name\", inplace = True)\n",
    "Features.drop(columns = \"end_station_name\", inplace = True)\n",
    "Features.drop(columns = \"bike_id\", inplace = True)\n",
    "Features.drop(columns = \"user_type\", inplace = True)\n",
    "\n",
    "Features.rename(columns = {\"end_time\": \"Rides\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting df can be double checked with one of the cells above or with the sorted Rides df. It seems reasonable though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Features.iloc[0][\"Rides\"]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features[\"Rides_last_hour\"] = 0\n",
    "value = Features.iloc[0][\"Rides\"]\n",
    "for i in Features.index:     \n",
    "        Features.loc[i,\"Rides_last_hour\"] = value\n",
    "        value = Features.loc[i][\"Rides\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some erroneous data in the weather data set as there are rows which exhibit the same date, leading pandas to crash. (e.g. for index 1662, if duplicates were not removed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weather = pd.read_csv(\"weather_hourly_chicago.csv\", sep=\",\")\n",
    "\n",
    "Weather[\"avg_tmp\"] = (Weather[\"max_temp\"]+Weather[\"min_temp\"])/2\n",
    "Weather[\"is_raining\"] = Weather[\"precip\"] == 1\n",
    "Weather.drop(columns = [\"max_temp\", \"min_temp\", \"precip\"], inplace=True)\n",
    "\n",
    "Weather[\"date_time\"] = pd.to_datetime(Weather[\"date_time\"])\n",
    "\n",
    "Weather.set_index(\"date_time\", inplace = True)\n",
    "Features = Features.join(Weather, on=\"start_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of missing values for weather, imputation methods:\n",
    "\n",
    "* numerical values: linear interpolation (time series data)\n",
    "* categorical (is_raining): backwards-fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features.interpolate(inplace=True)\n",
    "Features.fillna(method=\"bfill\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features[Features[\"is_raining\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Features[Features[\"is_raining\"] == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features[\"is_workday\"] = Features[\"start_time\"].apply(lambda x: x.weekday() < 5)\n",
    "Features[\"hour\"] = Features[\"start_time\"].apply(lambda x: x.hour)\n",
    "Features[\"month\"] = Features[\"start_time\"].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSeason(month):\n",
    "    \n",
    "    Winter = [12, 1, 2]\n",
    "    Spring = [3, 4, 5]\n",
    "    Summer = [6, 7, 8]\n",
    "    Fall = [9, 10, 11]\n",
    "    \n",
    "    if month in Winter:\n",
    "        return 1\n",
    "    elif month in Spring:\n",
    "        return 2\n",
    "    elif month in Summer:\n",
    "        return 3\n",
    "    elif month in Fall:\n",
    "        return 4\n",
    "    \n",
    "Features[\"season\"] = Features[\"month\"].apply(lambda month: getSeason(month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = pd.get_dummies(Features[\"season\"],prefix=\"season_\")\n",
    "seasons.drop(columns=\"season__4\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features[list(seasons.columns)] = seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = pd.get_dummies(Features[\"hour\"],prefix=\"hour_\")\n",
    "hours.drop(columns=\"hour__23\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features[list(hours.columns)] = hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features.drop(columns=[\"season\",\"month\",\"hour\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_rescaled = pd.DataFrame()\n",
    "\n",
    "Features_rescaled[\"Rides\"] = (Features[\"Rides\"] - Features[\"Rides\"].min()) / (Features[\"Rides\"].max() - Features[\"Rides\"].min())\n",
    "Features_rescaled[\"Rides_last_hour\"] = (Features[\"Rides_last_hour\"] - Features[\"Rides_last_hour\"].min()) / (Features[\"Rides_last_hour\"].max() - Features[\"Rides_last_hour\"].min())\n",
    "Features_rescaled[\"Max_temp\"] = (Features[\"Max_temp\"] - Features[\"Max_temp\"].min()) / (Features[\"Max_temp\"].max() - Features[\"Max_temp\"].min())\n",
    "Features_rescaled[\"Min_temp\"] = (Features[\"Min_temp\"] - Features[\"Min_temp\"].min()) / (Features[\"Min_temp\"].max() - Features[\"Min_temp\"].min())\n",
    "Features_rescaled[\"Precipitation\"] = (Features[\"Precipitation\"] - Features[\"Precipitation\"].min()) / (Features[\"Precipitation\"].max() - Features[\"Precipitation\"].min())\n",
    "Features_rescaled[\"Day_of_Week\"] = (Features[\"Day_of_Week\"] - Features[\"Day_of_Week\"].min()) / (Features[\"Day_of_Week\"].max() - Features[\"Day_of_Week\"].min())\n",
    "Features_rescaled[\"Hour\"] = (Features[\"Hour\"] - Features[\"Hour\"].min()) / (Features[\"Hour\"].max() - Features[\"Hour\"].min())\n",
    "Features_rescaled[\"Month\"] = (Features[\"Month\"] - Features[\"Month\"].min()) / (Features[\"Month\"].max() - Features[\"Month\"].min())\n",
    "Features_rescaled[\"Season\"] = (Features[\"Season\"] - Features[\"Season\"].min()) / (Features[\"Season\"].max() - Features[\"Season\"].min())\n",
    "\n",
    "Features_rescaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=Features[\"start_time\"], y=Features_rescaled[\"Rides\"],\n",
    "                    mode='lines',\n",
    "                    name='Demand'))\n",
    "fig.add_trace(go.Scatter(x=Features[\"start_time\"], y=Features_rescaled[\"Max_temp\"],\n",
    "                    mode='lines+markers',\n",
    "                    name='Max. Temperature'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x = \"avg_tmp\", y = \"Rides\", data = Features, kind = \"hex\", height=10, palette = \"magma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(Features, palette=\"magma\", height=3, hue=\"is_raining\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_corr = Features.corr()\n",
    "Features_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Features_corr, \n",
    "        xticklabels=Features_corr.columns,\n",
    "        yticklabels=Features_corr.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://stackoverflow.com/questions/39409866/correlation-heatmap) for the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)\n",
    "\n",
    "def magnify():\n",
    "    return [dict(selector=\"th\",\n",
    "                 props=[(\"font-size\", \"7pt\")]),\n",
    "            dict(selector=\"td\",\n",
    "                 props=[('padding', \"0em 0em\")]),\n",
    "            dict(selector=\"th:hover\",\n",
    "                 props=[(\"font-size\", \"12pt\")]),\n",
    "            dict(selector=\"tr:hover td:hover\",\n",
    "                 props=[('max-width', '200px'),\n",
    "                        ('font-size', '12pt')])\n",
    "]\n",
    "\n",
    "Features_corr.style.background_gradient(cmap, axis=1)\\\n",
    "    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n",
    "    .set_caption(\"Hover to magify\")\\\n",
    "    .set_precision(2)\\\n",
    "    .set_table_styles(magnify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_rescaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_sample = Features[3100:3220]\n",
    "Features_sample = Features_sample[Features[\"avg_tmp\"] != 0]\n",
    "#Features_sample = Features.sample(n=125)\n",
    "#Features_sample = Features_sample[Features[\"Max_temp\"] != 0]\n",
    "\n",
    "sns.scatterplot(x = Features_sample[\"avg_tmp\"], y = Features_sample[\"Rides\"], hue = Features_sample[\"is_raining\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.density_heatmap(Features, x='avg_tmp', y='Rides', width=600, height=600,\n",
    "                      title='Correlation between Temperature and Demand', color_continuous_scale=[[0.0, 'white'], [1.0, 'red']],\n",
    "                        nbinsx=25, nbinsy=25)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.parallel_coordinates(data_frame = Features, dimensions =[\"\"])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(data_frame = Features_sample, z='Max_temp', x='Rides', y='Hour', color='Precipitation', opacity=0.4, size_max=5)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(data_frame = Features_sample, z='Max_temp', x='Rides', y='Rides_last_hour', color='Precipitation', opacity=0.4, size_max=5)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data with 70-30% split as above\n",
    "\n",
    "X = Features[Features.columns[(Features.columns != \"Rides\") & (Features.columns != \"start_time\")]]\n",
    "y = Features[\"Rides\"]\n",
    "X,y\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fangt hier an..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
